diff --git a/lmcache/integration/vllm/utils.py b/lmcache/integration/vllm/utils.py
index 4692f00..bd2d86f
--- a/lmcache/integration/vllm/utils.py
+++ b/lmcache/integration/vllm/utils.py
@@ -55,6 +55,8 @@ def lmcache_get_or_create_config() -> Union[Config, V1Config]:
                     )
                     LMCacheEngineConfig = Config  # type: ignore[assignment]
                 else:
+                    from lmcache_ascend.v1.config import _validate_config
+                    V1Config.validate = _validate_config
                     LMCacheEngineConfig = V1Config  # type: ignore[assignment]
 
                 if "LMCACHE_CONFIG_FILE" not in os.environ:

diff --git a/lmcache/v1/storage_backend/storage_manager.py b/lmcache/v1/storage_backend/storage_manager.py
index 51c4788..07147e4 100755
--- a/lmcache/v1/storage_backend/storage_manager.py
+++ b/lmcache/v1/storage_backend/storage_manager.py
@@ -224,12 +224,14 @@ class StorageManager:
         self.event_manager = event_manager
 
         self.async_lookup_server: Optional["LMCacheAsyncLookupServer"] = None
+        self.async_serializer: Optional[AsyncSerializer] = None
 
         # The cuda stream for internal copies during put
         if torch.cuda.is_available():
             self.internal_copy_stream = torch.cuda.Stream()
         else:
             self.internal_copy_stream = None
+        self.async_serializer = AsyncSerializer(self.allocator_backend, self.loop)
 
     def post_init(self, **kwargs) -> None:
         if "async_lookup_server" in kwargs:
@@ -420,15 +422,15 @@ class StorageManager:
             # Retrieve all chunks for one layer
             backend = self.storage_backends[location]
             # TODO(Jiayi): need to make async loading and layerwise compatible
-            task = asyncio.run_coroutine_threadsafe(
-                self.async_serializer.run(
-                    backend.batched_get_non_blocking(
-                        "fake_lookup_id", keys_multi_chunk
-                    ),
-                    len(keys_multi_chunk),
-                ),
-                self.loop,
+            assert self.async_serializer is not None, (
+                "Async serializer must be initialized via post_init before using "
+                "layerwise_batched_get."
+            )
+            coro = self.async_serializer.run(
+                backend.batched_get_non_blocking("fake_lookup_id", keys_multi_chunk),
+                len(keys_multi_chunk),
             )
+            task = asyncio.run_coroutine_threadsafe(coro, self.loop)
             yield task
 
     def prefetch_single_done_callback(
@@ -516,16 +518,19 @@ class StorageManager:
 
             num_total_hit_chunks += num_hit_chunks
 
-            loading_task = asyncio.create_task(
-                self.async_serializer.run(
-                    backend.batched_get_non_blocking(
-                        lookup_id,
-                        keys[:num_hit_chunks],
-                        {"cum_chunk_lengths": cum_chunk_lengths[: num_hit_chunks + 1]},
-                    ),
-                    num_hit_chunks,
-                )
+            assert self.async_serializer is not None, (
+                "Async serializer must be initialized via post_init before using "
+                "async_lookup_and_prefetch."
             )
+            get_coro = self.async_serializer.run(
+                backend.batched_get_non_blocking(
+                    lookup_id,
+                    keys[:num_hit_chunks],
+                    {"cum_chunk_lengths": cum_chunk_lengths[: num_hit_chunks + 1]},
+                ),
+                num_hit_chunks,
+            )    
+            loading_task = asyncio.create_task(get_coro)
             loading_task.add_done_callback(
                 functools.partial(
                     self.prefetch_single_done_callback,
