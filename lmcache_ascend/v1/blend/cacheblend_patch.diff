diff --git a/lmcache/v1/config.py b/lmcache/v1/config.py
old mode 100755
new mode 100644
index 785e9bd..a2cd000
--- a/lmcache/v1/config.py
+++ b/lmcache/v1/config.py
@@ -435,7 +435,7 @@ def _create_config_class():
 def _validate_config(self):
     """Validate configuration"""
     # auto-adjust save_unfull_chunk for async loading to prevent CPU fragmentation
-    if self.enable_async_loading or self.use_layerwise:
+    if self.enable_async_loading:
         logger.warning(
             "Automatically setting save_unfull_chunk=False because "
             "enable_async_loading=True or use_layerwise=True to prevent "
@@ -443,6 +443,14 @@ def _validate_config(self):
         )
         self.save_unfull_chunk = False
 
+    if self.enable_blending:
+        if not self.save_unfull_chunk:
+            logger.warning(
+                "Automatically setting save_unfull_chunk=True because "
+                "enable_blending=True"
+            )
+            self.save_unfull_chunk = True
+
     if self.enable_p2p:
         assert self.enable_controller
         assert self.controller_pull_url is not None

diff --git a/lmcache/v1/storage_backend/storage_manager.py b/lmcache/v1/storage_backend/storage_manager.py
index 51c4788..07147e4 100755
--- a/lmcache/v1/storage_backend/storage_manager.py
+++ b/lmcache/v1/storage_backend/storage_manager.py
@@ -224,12 +224,14 @@ class StorageManager:
         self.event_manager = event_manager
 
         self.async_lookup_server: Optional["LMCacheAsyncLookupServer"] = None
+        self.async_serializer: Optional[AsyncSerializer] = None
 
         # The cuda stream for internal copies during put
         if torch.cuda.is_available():
             self.internal_copy_stream = torch.cuda.Stream()
         else:
             self.internal_copy_stream = None
+        self.async_serializer = AsyncSerializer(self.allocator_backend, self.loop)
 
     def post_init(self, **kwargs) -> None:
         if "async_lookup_server" in kwargs:
@@ -420,15 +422,15 @@ class StorageManager:
             # Retrieve all chunks for one layer
             backend = self.storage_backends[location]
             # TODO(Jiayi): need to make async loading and layerwise compatible
-            task = asyncio.run_coroutine_threadsafe(
-                self.async_serializer.run(
-                    backend.batched_get_non_blocking(
-                        "fake_lookup_id", keys_multi_chunk
-                    ),
-                    len(keys_multi_chunk),
-                ),
-                self.loop,
+            assert self.async_serializer is not None, (
+                "Async serializer must be initialized via post_init before using "
+                "layerwise_batched_get."
+            )
+            coro = self.async_serializer.run(
+                backend.batched_get_non_blocking("fake_lookup_id", keys_multi_chunk),
+                len(keys_multi_chunk),
             )
+            task = asyncio.run_coroutine_threadsafe(coro, self.loop)
             yield task
 
     def prefetch_single_done_callback(
@@ -516,16 +518,19 @@ class StorageManager:
 
             num_total_hit_chunks += num_hit_chunks
 
-            loading_task = asyncio.create_task(
-                self.async_serializer.run(
-                    backend.batched_get_non_blocking(
-                        lookup_id,
-                        keys[:num_hit_chunks],
-                        {"cum_chunk_lengths": cum_chunk_lengths[: num_hit_chunks + 1]},
-                    ),
-                    num_hit_chunks,
-                )
+            assert self.async_serializer is not None, (
+                "Async serializer must be initialized via post_init before using "
+                "async_lookup_and_prefetch."
             )
+            get_coro = self.async_serializer.run(
+                backend.batched_get_non_blocking(
+                    lookup_id,
+                    keys[:num_hit_chunks],
+                    {"cum_chunk_lengths": cum_chunk_lengths[: num_hit_chunks + 1]},
+                ),
+                num_hit_chunks,
+            )    
+            loading_task = asyncio.create_task(get_coro)
             loading_task.add_done_callback(
                 functools.partial(
                     self.prefetch_single_done_callback,
